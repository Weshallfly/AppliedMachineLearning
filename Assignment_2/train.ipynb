{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7017031f-a221-49e1-8bb3-404940bed73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score,roc_curve, auc, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9aa0ab-af96-4f52-9cd9-b0eda05a9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "val_data = pd.read_csv(\"./val.csv\")\n",
    "test_data = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184477b1-1e22-41e1-9207-7fcbf5339700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message    5\n",
      "label      0\n",
      "dtype: int64 message    0\n",
      "label      0\n",
      "dtype: int64 message    1\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum(), val_data.isnull().sum(), test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820ba027-3cea-4d0d-aa4e-1211c524934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs in any column\n",
    "train_data = train_data.dropna()\n",
    "val_data = val_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "X_train, y_train = train_data.drop(columns=\"label\"), train_data[\"label\"].values\n",
    "X_val, y_val = val_data.drop(columns=\"label\"), val_data[\"label\"].values\n",
    "X_test, y_test = test_data.drop(columns=\"label\"), test_data[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44902e60-5fcc-4fae-a9bd-372dce41ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = vectorizer.fit_transform(X_train['message'])\n",
    "\n",
    "# Transform the validation and test data\n",
    "X_val = vectorizer.transform(X_val['message'])\n",
    "X_test = vectorizer.transform(X_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d7e22-b361-41e7-aaf8-3b6e823703c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 00:06:28 INFO mlflow.tracking.fluent: Experiment with name 'Benchmark_Models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Best Params: {'C': 10, 'penalty': 'l2'}\n",
      "Validation Accuracy: 0.9709\n",
      "AUC ROC Score: 0.9798\n",
      "AUCPR Score: 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic Regression'.\n",
      "Created version '1' of model 'Logistic Regression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression logged and registered in MLflow.\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Best Params: {'max_depth': None, 'n_estimators': 200}\n",
      "Validation Accuracy: 0.9619\n",
      "AUC ROC Score: 0.9902\n",
      "AUCPR Score: 0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest'.\n",
      "Created version '1' of model 'Random Forest'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest logged and registered in MLflow.\n",
      "\n",
      "\n",
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"Benchmark_Models\")\n",
    "input_example = X_test[:1].toarray() \n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"param_grid\": {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"param_grid\": {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, None]},\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(probability=True),\n",
    "        \"param_grid\": {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    },\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "\n",
    "for model_name, details in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "        # Grid Search for Hyperparameter tuning\n",
    "        search = GridSearchCV(details[\"model\"], details[\"param_grid\"], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        search.fit(X_train, y_train)\n",
    "        best_model = search.best_estimator_\n",
    "        best_models[model_name] = best_model\n",
    "        \n",
    "        # Validation Accuracy\n",
    "        val_accuracy = accuracy_score(y_val, best_model.predict(X_val))\n",
    "        \n",
    "        # Test predictions\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # AUC ROC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr')\n",
    "        \n",
    "        # AUCPR Score\n",
    "        aucpr = average_precision_score(y_test, y_test_prob)\n",
    "        \n",
    "        print(f\"Best Params: {search.best_params_}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"AUC ROC Score: {roc_auc:.4f}\")\n",
    "        print(f\"AUCPR Score: {aucpr:.4f}\")\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_params(search.best_params_)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"aucpr\", aucpr)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(sk_model=best_model,artifact_path=model_name,input_example=input_example)\n",
    "        \n",
    "        # Register best model\n",
    "        mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/{model_name}\", model_name)\n",
    "\n",
    "        print(f\"{model_name} logged and registered in MLflow.\\n\")\n",
    "\n",
    "print(\"All models trained and logged in MLflow successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f6ce8-aea1-4a10-a92e-5d5e55dd2045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
